{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EuroScipy2018",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/mr-ubik/gans-from-theory-to-production/blob/master/EuroScipy2018.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "6PGn9wjLC8mK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BZC-9DUf-JnX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/zurutech/gans-from-theory-to-production"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xltSg8GI-YX0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd gans-from-theory-to-production/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q2ts2PkT-cOa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QEU_yYT--fn_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python prepare_celeba_dataset.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TBQ7Z6hpF4an",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm ngrok*\n",
        "\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "LOG_DIR = './logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8S-waC_E-k_B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorboardcolab\n",
        "\n",
        "tfgan = tf.contrib.gan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ldK1zjbk_nKe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def deconv2d(inputs, filters, strides=(1, 1), activation=tf.nn.relu):\n",
        "    \"\"\"\\\"Deconvolution\\\" layer.\n",
        "    \n",
        "    It uses upsampling with nearest neighbor interpolation to reduce the\n",
        "    presence of checkboard artifacts.\n",
        "    \"\"\"\n",
        "    \n",
        "    input_h, input_w = inputs.shape[1].value, inputs.shape[2].value\n",
        "    layer_1 = tf.image.resize_nearest_neighbor(\n",
        "        inputs, (2 * input_h, 2 * input_w), name=\"NNUpSample2D\"\n",
        "    )\n",
        "    # Padding before convolution is used to reduce boundary artifacts\n",
        "    layer_1 = tf.pad(layer_1, [[0, 0], [2, 2], [2, 2], [0, 0]], mode=\"CONSTANT\")\n",
        "    layer_2 = tf.layers.conv2d(\n",
        "        inputs=layer_1,\n",
        "        filters=filters,\n",
        "        kernel_size=5,\n",
        "        padding=\"valid\",\n",
        "        use_bias=False,\n",
        "        activation=activation,\n",
        "        strides=strides,\n",
        "    )\n",
        "    return layer_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O4F42qZ9_omD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator_fn(inputs, mode):\n",
        "    \"\"\"Generator producing images from noise.\n",
        "\n",
        "        Args:\n",
        "            noise: A single Tensor representing noise.\n",
        "            mode: tf.estimator.ModeKeys\n",
        "\n",
        "        Returns:\n",
        "            A 64x64 (None, 4096) flattened tensor whose values are\n",
        "            inside the (-1, 1) range.\"\"\"\n",
        "    is_training = mode == tf.estimator.ModeKeys.TRAIN\n",
        "    linear = tf.layers.dense(inputs=inputs, units=1024 * 4 * 4, activation=tf.nn.relu)\n",
        "    net = tf.reshape(linear, (-1, 4, 4, 1024))\n",
        "    net = tf.layers.batch_normalization(net, training=is_training)\n",
        "    net = deconv2d(net, 512)\n",
        "    net = tf.layers.batch_normalization(net, training=is_training)\n",
        "    net = deconv2d(net, 256)\n",
        "    net = tf.layers.batch_normalization(net, training=is_training)\n",
        "    net = deconv2d(net, 128)\n",
        "    net = tf.layers.batch_normalization(net, training=is_training)\n",
        "    net = deconv2d(net, 64)\n",
        "    net = tf.layers.conv2d(\n",
        "        inputs=net,\n",
        "        filters=3,\n",
        "        kernel_size=5,\n",
        "        padding=\"same\",\n",
        "        data_format=\"channels_last\",\n",
        "        use_bias=False,\n",
        "        strides=(1, 1),)\n",
        "    output = tf.tanh(net)\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gq5Kwtax_raN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def custom_conv2d(inputs, filters, strides=(2,2)):\n",
        "    \"\"\"Helper layer used to instatiate `tf.layers.conv2d` with proper arguments.\"\"\"\n",
        "    layer_1 = tf.layers.conv2d(\n",
        "        inputs=inputs,\n",
        "        filters=filters,\n",
        "        kernel_size=5,\n",
        "        padding=\"same\",\n",
        "        data_format=\"channels_last\",\n",
        "        use_bias=False,\n",
        "        strides=strides,\n",
        "    )\n",
        "    layer_1 = tf.nn.leaky_relu(layer_1, alpha=0.2)\n",
        "\n",
        "    return layer_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TnKVrNyA_vHD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def discriminator_fn(inputs, conditioning, mode):\n",
        "    \"\"\"Build the Discriminator network.\n",
        "    Args:\n",
        "        features: a batch of images to classify, expected input shape (None, 64, 64 , 3)\n",
        "        conditioning: a batch of labels, it is used for conditioning in the some model (es Conditional GAN).\n",
        "            GANEstimator wants this parameters around, just define an arguments so that discriminator_fn is not broken.\n",
        "        mode: tf.estimator.ModeKey\n",
        "    \n",
        "    Returns:\n",
        "            The output (logits) of the discriminator.\n",
        "    \"\"\"\n",
        "    \n",
        "    # In every mode, define the model\n",
        "    is_training = mode == tf.estimator.ModeKeys.TRAIN\n",
        "    net = custom_conv2d(inputs, filters=64)\n",
        "    net = custom_conv2d(inputs, filters=128)\n",
        "    net = tf.layers.batch_normalization(net, training=is_training)\n",
        "    net = custom_conv2d(net, filters=256)\n",
        "    net = tf.layers.batch_normalization(net, training=is_training)\n",
        "    net = custom_conv2d(net, filters=512)\n",
        "    net = tf.layers.batch_normalization(net, training=is_training)\n",
        "    net = custom_conv2d(net, filters=1024)\n",
        "    net = tf.layers.batch_normalization(net, training=is_training)\n",
        "    net = tf.reshape(net, (-1, net.shape[1] * net.shape[2] * net.shape[3]))\n",
        "    output = tf.layers.dense(net, units=1)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EnHEVGuq_yFw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _get_train_images_input_fn(file_pattern, image_size=(64, 64, 3), shuffle=False,\n",
        "                 batch_size=32, num_epochs=None, buffer_size=4096):\n",
        "    \"\"\"get_input_fn exploits the `file_pattern` to create an input_fn that reads all the content\n",
        "    of the specified pattern, creating an object dataset.\n",
        "    \n",
        "    Args:\n",
        "        file_pattern: python string, the pattern of the file to read to generate the dataset\n",
        "        image_size: the new size of the read images\n",
        "        shuffle: True if the order of the elements in the generated dataset shold be randomized\n",
        "        batch_size: the size of the batches\n",
        "        num_epochs: the number of epochs to repeat the dataset before throwing an exeption; None is unlimited\n",
        "        buffer_size: how many images read before starting to generate output\n",
        "    Returns:\n",
        "        input_fn: the generated input_fn that returns a correctly instantiated iterator\n",
        "    \"\"\"\n",
        "    \n",
        "    def _img_string_to_tensor(image_string):\n",
        "        \"\"\"Decode an image as read from a `tf.decode_raw`, scales it between 0-1 and resize the\n",
        "        image as specified in the parent method.\n",
        "        Args:\n",
        "            image_string: the raw image tensor\n",
        "        Returns:\n",
        "            image_resize: image in [0,1] correctly resized\n",
        "        \"\"\"\n",
        "        \n",
        "        nonlocal image_size\n",
        "        \n",
        "        image_decoded = tf.image.decode_jpeg(image_string, channels=image_size[-1])\n",
        "        # The conversion to float automatically scales the values in [0., 1.]\n",
        "        image_decoded_as_float = tf.image.convert_image_dtype(image_decoded, dtype=tf.float32)\n",
        "        image_decoded = (image_decoded_as_float - 0.5) * 2\n",
        "        image_resized = tf.image.resize_images(image_decoded, size=image_size[:2])\n",
        "        \n",
        "\n",
        "        return image_resized\n",
        "\n",
        "    def _path_to_img(path):\n",
        "        \"\"\"Given the path of an image, returns the pair (image, label)\n",
        "        where image is the corretly resized image, and label is the label associated with it.\n",
        "        Args:\n",
        "            path: the path of the image to read\n",
        "        Returns:\n",
        "            (image_resized, label): the image, label pair associated the path\n",
        "        \"\"\"\n",
        "        \n",
        "        # Get the parent folder of this file to get its class\n",
        "        # Associate the label 0 to dogs and 1 to cats\n",
        "        label = tf.cond(\n",
        "                    tf.equal(tf.string_split([path], delimiter='/').values[-2], \"dogs\"),\n",
        "                    lambda: 0, lambda: 1)\n",
        "\n",
        "        image_string = tf.read_file(path) # read image and process it\n",
        "        image_resized = _img_string_to_tensor(image_string)\n",
        "\n",
        "        return image_resized, label\n",
        "    \n",
        "    def _input_fn():\n",
        "        \"\"\"The input function that builds the `tf.data.Dataset` object and instantiate\n",
        "        the iterator correctly ready to be use.\n",
        "        Returns:\n",
        "            the iterator associated to the built Dataset object.\n",
        "        \"\"\"\n",
        "        \n",
        "        # Use the static method `list_files` that builds a dataset of all\n",
        "        # files matching this pattern.\n",
        "        dataset_path = tf.data.Dataset.list_files(file_pattern)\n",
        "\n",
        "        if shuffle:\n",
        "            dataset_path = dataset_path.apply(tf.contrib.data.shuffle_and_repeat(buffer_size, num_epochs))\n",
        "        else:\n",
        "            dataset_path = dataset_path.repeat(num_epochs)\n",
        "\n",
        "        # The map function maps the path to the pair (image, label)\n",
        "        dataset = dataset_path.map(_path_to_img)\n",
        "        dataset = dataset.apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\n",
        "        dataset = dataset.prefetch(buffer_size)\n",
        "        \n",
        "        iterator = dataset.make_one_shot_iterator()\n",
        "        return iterator.get_next()\n",
        "\n",
        "    return _input_fn()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3aPRypsa_0fR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _get_train_input_fn(file_pattern, batch_size, num_epochs, noise_dims=100, **kwargs):\n",
        "    def train_input_fn():\n",
        "        real_data = _get_train_images_input_fn(\n",
        "                 file_pattern,\n",
        "                 batch_size=batch_size, \n",
        "                 num_epochs=num_epochs)\n",
        "        noise = tf.random_normal([batch_size, noise_dims], name=\"train_noise\")\n",
        "        real_data.set_shape((batch_size,) + tuple(real_data.shape[1:]))\n",
        "        print(noise, real_data)\n",
        "        return noise, real_data\n",
        "    return train_input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6IF3vzHW_2pl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_hyperparameters():\n",
        "    hp = {\n",
        "        \"model_dir\": \"logs\",\n",
        "        \"file_pattern\": \"assets/celeba/*.jpg\",\n",
        "        \"batch_size\": 128,\n",
        "        \"num_epochs\":50,\n",
        "        \"noise_dims\": 100\n",
        "    }\n",
        "    return hp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5HejREAj_51L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dcgan():\n",
        "    \n",
        "    # Set the seed at a Graph Level so that we geet consistency between runs.\n",
        "    tf.set_random_seed(42)\n",
        "    \n",
        "    # Hyperparameters\n",
        "    hyperparameters = load_hyperparameters()\n",
        "    \n",
        "    # Run Configuration (it has other arguments)\n",
        "    run_config = tf.estimator.RunConfig(\n",
        "        model_dir=hyperparameters.get(\"model_dir\"), save_summary_steps=50, save_checkpoints_steps=500)\n",
        "    \n",
        "    # Instatiate the GANEstimator object\n",
        "    gan_estimator = tfgan.estimator.GANEstimator(\n",
        "        config=run_config,\n",
        "        generator_fn=generator_fn,\n",
        "        discriminator_fn=discriminator_fn,\n",
        "        generator_loss_fn=tfgan.losses.modified_generator_loss,\n",
        "        discriminator_loss_fn=tfgan.losses.modified_discriminator_loss,\n",
        "        generator_optimizer=tf.train.AdamOptimizer(0.0002, 0.5),\n",
        "        discriminator_optimizer=tf.train.AdamOptimizer(0.0002, 0.5),\n",
        "        add_summaries=tfgan.estimator.SummaryType.IMAGES\n",
        "    )\n",
        "    \n",
        "    # Instatiate the train_input_fn\n",
        "    # The model will train until it exhausts the Dataset which is repeated EPOCH times\n",
        "    train_input_fn = _get_train_input_fn(**hyperparameters)\n",
        "    trained_model = gan_estimator.train(train_input_fn, max_steps=None)\n",
        "    return trained_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "atWw9CinAHut",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _predict_input_fn(batch_size, noise_dims=100, **kwargs):\n",
        "    \n",
        "    def predict_input_fn():\n",
        "        noise_gen = np.array([np.float32(np.random.normal(size=[1, noise_dims])) for i in range(batch_size)])\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(noise_gen)\n",
        "        dataset = dataset.batch(batch_size)\n",
        "        iterator = dataset.make_one_shot_iterator()\n",
        "        return iterator.get_next()\n",
        "        \n",
        "    return predict_input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IOYG6tbPBwSK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trained_model = dcgan()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LOqgMsWQAJjR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions_batch = 16\n",
        "predict_input_fn = _predict_input_fn(batch_size=predictions_batch)\n",
        "predictions = trained_model.predict(predict_input_fn)\n",
        "new_celebs = [next(predictions) for _ in range(predictions_batch)]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}