{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/logo.jpg\" style=\"width:85px;height:85px;float:left\" /><h1 style=\"position:relative;float:left;display:inline\">Serving GANs in Production with Google Cloud ML engine</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='https://colab.research.google.com/github/zurutech/gans-from-theory-to-production/blob/master/4.%20Production/4.1.%20Serving%20GANs.ipynb'>\n",
    "  <img align='left' alt='Try it in a a Colab Notebook' src='https://cdn-images-1.medium.com/max/800/1*ZpNn76K98snC9vDiIJ6Ldw.jpeg'></img>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#CloudML-Engine\" data-toc-modified-id=\"CloudML-Engine-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>CloudML Engine</a></span><ul class=\"toc-item\"><li><span><a href=\"#Predict\" data-toc-modified-id=\"Predict-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Predict</a></span></li><li><span><a href=\"#Why-CloudML\" data-toc-modified-id=\"Why-CloudML-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Why CloudML</a></span></li></ul></li><li><span><a href=\"#Getting-the-Model-Online\" data-toc-modified-id=\"Getting-the-Model-Online-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span><a href=\"https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models\" target=\"_blank\">Getting the Model Online</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-the-bucket\" data-toc-modified-id=\"Create-the-bucket-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Create the bucket</a></span></li><li><span><a href=\"#Upload-the-saved-and-exported-model-to-Google-Cloud-Storage\" data-toc-modified-id=\"Upload-the-saved-and-exported-model-to-Google-Cloud-Storage-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Upload the saved and exported model to Google Cloud Storage</a></span></li><li><span><a href=\"#Create-a-CloudML-Engine-Model\" data-toc-modified-id=\"Create-a-CloudML-Engine-Model-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Create a CloudML Engine Model</a></span></li><li><span><a href=\"#Create-a-new-version-of-the-model\" data-toc-modified-id=\"Create-a-new-version-of-the-model-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Create a new version of the model</a></span></li></ul></li><li><span><a href=\"#Predictions\" data-toc-modified-id=\"Predictions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Predictions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Online-Predictions\" data-toc-modified-id=\"Online-Predictions-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span><a href=\"https://cloud.google.com/ml-engine/docs/tensorflow/online-predict\" target=\"_blank\">Online Predictions</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#GCLOUD\" data-toc-modified-id=\"GCLOUD-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>GCLOUD</a></span></li><li><span><a href=\"#Python-[code-by-Google]\" data-toc-modified-id=\"Python-[code-by-Google]-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Python [code by Google]</a></span></li></ul></li><li><span><a href=\"#Batch-Predictions\" data-toc-modified-id=\"Batch-Predictions-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span><a href=\"https://cloud.google.com/ml-engine/docs/tensorflow/batch-predict\" target=\"_blank\">Batch Predictions</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-the-input-data-into-a-Google-Cloud-Storage\" data-toc-modified-id=\"Load-the-input-data-into-a-Google-Cloud-Storage-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Load the input data into a Google Cloud Storage</a></span></li><li><span><a href=\"#GCLOUD\" data-toc-modified-id=\"GCLOUD-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>GCLOUD</a></span></li><li><span><a href=\"#Python-[code-by-Google]\" data-toc-modified-id=\"Python-[code-by-Google]-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Python [code by Google]</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Google Cloud Logo](images/google-cloud.png)\n",
    "\n",
    "\n",
    "![Google CloudML Engine Logo](images/google-cloud-ml-logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CloudML Engine\n",
    "\n",
    "\n",
    "> Google Cloud Machine Learning (ML) Engine is a managed service that enables developers and data scientists to build and bring superior machine learning models to production. Cloud ML Engine offers training and prediction services, which can be used together or individually. \n",
    "\n",
    "### Predict\n",
    "\n",
    "> Prediction incorporates intelligence into your applications and workflows. Once you have a trained model, prediction applies what the computer learned to new examples. ML Engine offers two types of prediction:\n",
    ">\n",
    "> [Online Prediction]() deploys ML models with serverless, fully managed hosting that responds in real time with high availability. Our global prediction platform automatically scales to adjust to any throughput. It provides a secure web endpoint to integrate ML into your applications.\n",
    ">\n",
    "> [Batch Prediction]() offers cost-effective inference with unparalleled throughput for asynchronous applications. It scales to perform inference on TBs of production data.\n",
    "\n",
    "### Why CloudML\n",
    "\n",
    "Deploying models using Google Cloud ML is not the only way to put TensorFlow model in production; however, we currently believe that the advantages of a fully managed/no-ops tool integrated into the Google Cloud environment make Cloud ML the best solution out there.\n",
    "\n",
    "While this workshop will only cover using Google CloudML for getting predictions, [here](https://cloud.google.com/ml-engine/docs/tensorflow/getting-started-training-prediction) you can find the complete documentation covering both training and a predicting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Getting the Model Online](https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models)\n",
    "\n",
    "> **Creating a model version**\n",
    ">\n",
    "> Cloud ML Engine organizes your trained models using model and version resources. A Cloud ML Engine model is a container for the versions of your machine learning model.\n",
    ">\n",
    "> You can find detailed information about the parameters that you need to deploy your model to Cloud ML Engine on the prediction concepts page.\n",
    ">\n",
    "> In order to deploy your trained model on Cloud ML Engine, you must:\n",
    ">\n",
    "> - Upload your SavedModel directory to a Cloud Storage bucket before you start.\n",
    "> - Create a Cloud ML Engine model resource.\n",
    "> - Create a Cloud ML Engine version resource, specifying the Cloud Storage path to your SavedModel.\n",
    "> - Ensure that your Cloud ML Engine service account has \"list\" access for the Cloud Storage bucket that contains your SavedModel, and \"read\" access for the SavedModel within the Cloud Storage bucket. Without the appropriate permissions, your request to create a version will fail. See more about granting permissions for storage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "REGION=\"europe-west1\"\n",
    "BUCKET_NAME=\"zuru-euroscipy2018-workshop\"\n",
    "gsutil mb -l $REGION gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the saved and exported model to Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "BUCKET_NAME=\"zuru-euroscipy2018-workshop\"\n",
    "GCS_MODEL_DIR=\"models\"\n",
    "MODEL_NAME=\"DCGANCelebA\"\n",
    "MODEL_DIR=\"../assets/exported_models/\"\n",
    "VERSION_NAME=\"praiseourlordgoodfellow\"\n",
    "\n",
    "# Be sure to updatae this variable with your model id \n",
    "MODEL_ID=\"1535124551\"\n",
    "\n",
    "gsutil -m cp -r $MODEL_DIR/$MODEL_ID/* gs://$BUCKET_NAME/$GCS_MODEL_DIR/$MODEL_NAME/$VERSION_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a CloudML Engine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "MODEL_NAME=\"DCGANCelebA\"\n",
    "REGION=\"europe-west1\"\n",
    "\n",
    "gcloud ml-engine models create $MODEL_NAME --regions $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new version of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "VERSION_NAME=\"praiseourlordgoodfellow\"\n",
    "BUCKET_NAME=\"zuru-euroscipy2018-workshop\"\n",
    "GCS_MODEL_DIR=\"models\"\n",
    "MODEL_NAME=\"DCGANCelebA\"\n",
    "MODEL_DIR=\"../assets/exported_models/\"\n",
    "DEPLOYMENT_SOURCE=\"gs://$BUCKET_NAME/$GCS_MODEL_DIR/$MODEL_NAME/$VERSION_NAME\"\n",
    "\n",
    "gcloud ml-engine versions delete $VERSION_NAME \\\n",
    "    --model $MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "VERSION_NAME=\"praiseourlordgoodfellow\"\n",
    "BUCKET_NAME=\"zuru-euroscipy2018-workshop\"\n",
    "GCS_MODEL_DIR=\"models\"\n",
    "MODEL_NAME=\"DCGANCelebA\"\n",
    "MODEL_DIR=\"../assets/exported_models/\"\n",
    "DEPLOYMENT_SOURCE=\"gs://$BUCKET_NAME/$GCS_MODEL_DIR/$MODEL_NAME/$VERSION_NAME\"\n",
    "\n",
    "gcloud ml-engine versions create $VERSION_NAME \\\n",
    "    --model $MODEL_NAME \\\n",
    "    --origin $DEPLOYMENT_SOURCE \\\n",
    "    --runtime-version=1.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Predictions\n",
    "\n",
    " Now that we have a working version of our model we can proceede to interrogage it for predictions.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Online Predictions](https://cloud.google.com/ml-engine/docs/tensorflow/online-predict)\n",
    "\n",
    "Request an online prediction by sending your input data instances as a JSON string in a predict request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GCLOUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "MODEL_NAME=\"DCGANCelebA\"\n",
    "INPUT_DATA_FILE=\"../assets/test_noise.ndjson\"\n",
    "VERSION_NAME=\"praiseourlordgoodfellow\"\n",
    "\n",
    "gcloud ml-engine predict \\\n",
    "    --model $MODEL_NAME  \\\n",
    "    --version $VERSION_NAME \\\n",
    "    --json-instances $INPUT_DATA_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python [code by Google]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_json(project, model, instances, version=None):\n",
    "    \"\"\"Send json data to a deployed model for prediction.\n",
    "\n",
    "    Args:\n",
    "        project (str): project where the Cloud ML Engine Model is deployed.\n",
    "        model (str): model name.\n",
    "        instances ([Mapping[str: Any]]): Keys should be the names of Tensors\n",
    "            your deployed model expects as inputs. Values should be datatypes\n",
    "            convertible to Tensors, or (potentially nested) lists of datatypes\n",
    "            convertible to tensors.\n",
    "        version: str, version of the model to target.\n",
    "    Returns:\n",
    "        Mapping[str: any]: dictionary of prediction results defined by the\n",
    "            model.\n",
    "    \"\"\"\n",
    "    # Create the ML Engine service object.\n",
    "    # To authenticate set the environment variable\n",
    "    # GOOGLE_APPLICATION_CREDENTIALS=<path_to_service_account_file>\n",
    "    service = googleapiclient.discovery.build('ml', 'v1')\n",
    "    name = 'projects/{}/models/{}'.format(project, model)\n",
    "\n",
    "    if version is not None:\n",
    "        name += '/versions/{}'.format(version)\n",
    "\n",
    "    response = service.projects().predict(\n",
    "        name=name,\n",
    "        body={'instances': instances}\n",
    "    ).execute()\n",
    "\n",
    "    if 'error' in response:\n",
    "        raise RuntimeError(response['error'])\n",
    "\n",
    "    return response['predictions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Batch Predictions](https://cloud.google.com/ml-engine/docs/tensorflow/batch-predict)\n",
    "\n",
    "When you don't need your predictions right away, or when you have a large number of instances to get predictions for, you can use the batch prediction service. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the input data into a Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "BUCKET_NAME=\"zuru-euroscipy2018-workshop\"\n",
    "PREDICT_INPUT_DATA_DIR=\"predictions_data\"\n",
    "MODEL_NAME=\"DCGANCelebA\"\n",
    "LOCAL_INPUT_DATA=\"../assets/test_noise.ndjson\"\n",
    "\n",
    "gsutil -m cp -r $LOCAL_INPUT_DATA gs://$BUCKET_NAME/$PREDICT_INPUT_DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GCLOUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "BUCKET_NAME=\"zuru-euroscipy2018-workshop\"\n",
    "PREDICT_INPUT_DATA_DIR=\"predictions_data\"\n",
    "PREDICT_OUTPUT_DATA_DIR=\"predictions\"\n",
    "MODEL_NAME=\"DCGANCelebA\"\n",
    "DATA_FORMAT=\"TEXT\"\n",
    "INPUT_PATHS=\"gs://$BUCKET_NAME/$PREDICT_INPUT_DATA_DIR\"\n",
    "OUTPUT_PATH=\"gs://$BUCKET_NAME/$PREDICT_OUTPUT_DATA_DIR\"\n",
    "MODEL_NAME=\"DCGANCelebA\"\n",
    "VERSION_NAME=\"praiseourlordgoodfellow\"\n",
    "REGION='europe-west1'\n",
    "now=$(date +\"%Y%m%d_%H%M%S\")\n",
    "JOB_NAME=\"euroscipy2018_$now\"\n",
    "MAX_WORKER_COUNT=\"20\"\n",
    "\n",
    "gcloud ml-engine jobs submit prediction $JOB_NAME \\\n",
    "    --model $MODEL_NAME \\\n",
    "    --input-paths $INPUT_PATHS \\\n",
    "    --output-path $OUTPUT_PATH \\\n",
    "    --region $REGION \\\n",
    "    --data-format $DATA_FORMAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python [code by Google]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery as discovery\n",
    "\n",
    "project_id = 'projects/{}'.format(project_name)\n",
    "\n",
    "ml = discovery.build('ml', 'v1')\n",
    "request = ml.projects().jobs().create(parent=project_id,\n",
    "                                      body=batch_predict_body)\n",
    "\n",
    "try:\n",
    "    response = request.execute()\n",
    "\n",
    "    print('Job requested.')\n",
    "\n",
    "    # The state returned will almost always be QUEUED.\n",
    "    print('state : {}'.format(response['state']))\n",
    "\n",
    "except errors.HttpError as err:\n",
    "    # Something went wrong, print out some information.\n",
    "    print('There was an error getting the prediction results.' +\n",
    "          'Check the details:')\n",
    "    print(err._get_reason())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "253px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
