{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFGAN to the Rescue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#TFGAN?\" data-toc-modified-id=\"TFGAN?-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>TFGAN?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Advantages\" data-toc-modified-id=\"Advantages-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Advantages</a></span></li><li><span><a href=\"#Caveats\" data-toc-modified-id=\"Caveats-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Caveats</a></span></li></ul></li><li><span><a href=\"#Inside-TFGAN\" data-toc-modified-id=\"Inside-TFGAN-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Inside TFGAN</a></span></li><li><span><a href=\"#GANModel-vs.-GANEstimator\" data-toc-modified-id=\"GANModel-vs.-GANEstimator-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>GANModel vs. GANEstimator</a></span></li><li><span><a href=\"#Links\" data-toc-modified-id=\"Links-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Links</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFGAN?\n",
    "\n",
    "TFGAN was developed by Google Brain (now Google AI) and released to the public on December 12, 2017 (see [blog post [1\\]](#1)); authored by Joel Shor and Sergio Guadarrama, TFGAN is a lightweight library built on top of TensorFlow (currently available under `contrib`) offering a one-stop solution for (almost) all of your GANs' training and evaluation needs.\n",
    "\n",
    "The code, documentation, and examples can be found both on TensorFlow website and on GitHub.\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- \"Double networks training,\" TFGAN offers an API that wraps a series of lower-level operations together resolving the headaches usually associated with the intertwined training of two different networks.\n",
    "- Popular, ready to use losses and penalties. \n",
    "- Pre-built summaries for monitoring and evaluating.\n",
    "- Pre-built commonly used evaluators like `Inception Score` or `Frechet Distance`.\n",
    "- \"Bag o' tricks\" AKA hacks, tricks and \"best practices\" highlighted in various papers that aid with training stability and quality. \n",
    "- Examples of complete Architecture based on the most cutting-edge research.\n",
    "- Supports defining custom GANs by building top of the `GANModel` objects.\n",
    "\n",
    "However, most importantly it offers `GANEstimator`, an API built upon TensorFlow own **Estimator API** that makes GANs' training a breeze.\n",
    "\n",
    "### Caveats\n",
    "\n",
    "It is not gold all that shines, while TFGAN is in our opinion the best way to build custom GANs, we feel that we should mention some of its drawbacks:\n",
    "\n",
    "- Contrib's woes: being part of `contrib` means that the library's API could change in a backward incompatible way while also having potentially more bugs (before TensorFlow 1.10 due to circa 4 lines of code trying to export a model built with `GANEstimator` for serving resulted in fatal crashes).\n",
    "- Building custom losses for TFGAN can be a pain due to the verbosity and \"low-levelness\" of the code that needs writing.\n",
    "- Due to the abstractions offered by a higher level API, especially when using `GANEstimator`, debugging or customizing the engine under the hood can sometimes be an annoying experience.\n",
    "\n",
    "## Inside TFGAN\n",
    "\n",
    "By taking a look at the [project structure [2\\]](#2), we can discover its functionalities.\n",
    "TFGAN is composed of several parts which were design to exist independently. These include the following main pieces:\n",
    "- Core: provides the core infrastructure needed to train a GAN. Training occurs in four phases, and each phase can be completed by custom-code or by using a TFGAN library call. The \"Core\" functions can be found in the `namedtuples.py` and `train.py`.\n",
    "- `estimator`: Estimator-like API that manages all the session related complexity for the developer, versatile and easy to use, `GANEstimator` inherits all the pros and cons of its parent. If you want to use the Estimator API (and you probably should), this is the way to use it with GANs without going insane from training two models together.\n",
    "- `features`: TFGAN implements many common GAN operations and normalization techniques for you to use, such instance normalization and conditioning.\n",
    "- `losses`: Easily experiment with already-implemented and well-tested losses and penalties, such as the Wasserstein loss, gradient penalty, mutual information penalty.\n",
    "- `eval`: Use `Inception Score` or `Frechet Distance` with a pre-trained Inception network to evaluate your unconditional generative model. You can also use your pre-trained classifier for more specific performance numbers, or use other methods for evaluating conditional generative models.\n",
    "- Examples and tutorial: these are provided under [TensorFlow Research Models [3\\]](#3) and contains a plethora of information on how to use TFGAN to make GAN training easier, or use the more complicated examples to jumpstart your project. These include unconditional and conditional GANs, InfoGANs, adversarial losses on existing networks, and image-to-image translation.\n",
    "\n",
    "## GANModel vs. GANEstimator\n",
    "\n",
    "While we focus our attention on `GANEstimator`, the real raw power of TFGAN is the flexibility offered by its lower level structures enabling the training of almost all kinds of GAN.\n",
    "\n",
    "> Training in TFGAN typically consists of the following steps:\n",
    "> 1. Specify the input to your networks.\n",
    "> 2. Set up your generator and discriminator using a `GANModel`.\n",
    "> 3. Specify your loss using a `GANLoss`.\n",
    "> 4. Create your train ops using a `GANTrainOps`.\n",
    "> 5. Run your train ops.\n",
    "\n",
    "For this workshop we decided to go with `GANEstimator` over `GANModel` for a couple of reason:\n",
    "\n",
    "- `Estimator API` is easier to learn, to use and is more suited for production deployment.\n",
    "- **DCGAN** (the GAN that powers up our demos) can be modeled and trained using `GANEstimator`.\n",
    "- Most of the TFGAN tutorials/examples focus on GANModel, and we wanted to increase the learning material covering `GANEstimator`.\n",
    "\n",
    "## Links\n",
    "\n",
    "<a id=\"1\">[1]</a>: https://ai.googleblog.com/2017/12/tfgan-lightweight-library-for.html\n",
    "\n",
    "<a id=\"2\">[2]</a>: \n",
    "https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/gan/python\n",
    "\n",
    "<a id=\"3\">[3]</a>: https://github.com/tensorflow/models/tree/master/research/gan/\n",
    "\n",
    "<a id=\"4\">[4]</a>: https://github.com/tensorflow/models/tree/master/research/gan/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "210.833px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
