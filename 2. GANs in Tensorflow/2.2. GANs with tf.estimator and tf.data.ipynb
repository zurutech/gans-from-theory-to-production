{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#GANs-with-tf.estimator-and-tf.data\" data-toc-modified-id=\"GANs-with-tf.estimator-and-tf.data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>GANs with tf.estimator and tf.data</a></span><ul class=\"toc-item\"><li><span><a href=\"#tf.estimator\" data-toc-modified-id=\"tf.estimator-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>tf.estimator</a></span></li><li><span><a href=\"#tf.data\" data-toc-modified-id=\"tf.data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>tf.data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Feeding-the-estimator:-create-the-input-pipeline\" data-toc-modified-id=\"Feeding-the-estimator:-create-the-input-pipeline-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Feeding the estimator: create the input pipeline</a></span></li></ul></li><li><span><a href=\"#DCGAN:-discriminator-using-tf.estimator\" data-toc-modified-id=\"DCGAN:-discriminator-using-tf.estimator-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>DCGAN: discriminator using tf.estimator</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANs with tf.estimator and tf.data\n",
    "\n",
    "In this notebook, we're going we try to define a GAN and its input data pipeline using the new APIs `tf.estimator` and `tf.data`. Our aim is to build a **cat/dog generator** (unconditional - but it can be easily extended to become a conditional GAN that generates cats or dogs, depending on a condition: this task is let to the reader).\n",
    "\n",
    "## tf.estimator\n",
    "\n",
    "Estimator have **a lot** of advantages, the official guide<sup>[1](#1)</sup> perfectly describes them:\n",
    "\n",
    "- You can run Estimator-based models on a local host or on a distributed multi-server environment without changing your model. Furthermore, you can run Estimator-based models on CPUs, GPUs, or TPUs without recoding your model.\n",
    "- Estimators simplify sharing implementations between model developers.\n",
    "- You can develop a state of the art model with high-level intuitive code. In short, it is generally much easier to create models with Estimators than with the low-level TensorFlow APIs.\n",
    "- Estimators are themselves built on tf.layers, which simplifies customization.\n",
    "- Estimators build the graph for you.\n",
    "- Estimators provide a safe distributed training loop that controls how and when to:\n",
    "    - build the graph\n",
    "    - initialize variables\n",
    "    - start queues\n",
    "    - handle exceptions\n",
    "    - create checkpoint files and recover from failures\n",
    "    - save summaries for TensorBoard\n",
    "\n",
    "When writing an application with Estimators, **you must separate the data input pipeline from the model**. This separation simplifies experiments with different data sets.\n",
    "\n",
    "In order to correclty separate the data input pipeline from the model, let's introduce `tf.data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.data\n",
    "\n",
    "The `tf.data` API has been designed to write complex input pipelines in a very simple manner. It uses the **named pattern idiom** (also called **method chaining**) and its methods are inspired to the functional programming languages that applies transformations to lists.\n",
    "\n",
    "The most imporant class is the `tf.data.Dataset` class that represents a sequence of elements: can apply transofrmation to this sequence of elements in order to create our dataset.\n",
    "\n",
    "Once the dataset has been correctly defined it can be used trough an `tf.data.Iterator` that provides a pythonic way (a python iterator) to extract elements from a dataset. For a more comprehensive description, refer to the official guide <sup>[2](#2)</sup>.\n",
    "\n",
    "\n",
    "### Feeding the estimator: create the input pipeline\n",
    "\n",
    "Every method of `tf.estimator` that requires input data (`train`, `evaluation`, `train_and_evalute`, `predict`) expects as first parameter a `input_fn`. This function should construct and return one of the following\n",
    "\n",
    "- A `tf.data.Dataset` object that once executed returns a tuple\n",
    "- A tuple\n",
    "\n",
    "The tuple can be the pair `(features, labels)` where features and labels can be batches. The cardinality of the tuple, however, is not constrained to be 2, it can be any: it depends on how we're going to use the return value of the `input_fn`.\n",
    "\n",
    "In the next few lines we're going to dowload and analyze the dataset (the well known cat vs dog dataset) and after that we will implement an helper function that will create various `input_fn` for us (depending if we're in training on in evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CelebA Dataset is already present, bravo.\r\n"
     ]
    }
   ],
   "source": [
    "! cd .. && python prepare_celeba_dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the dataset we can inspect its structure, in order to correctly build the input pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folder contains 202599 celebrities facees, cropped, aligned and already to the same size (178x218).\n",
    "\n",
    "Let's suppose that our model will generate images `64x64x3`, hence our `input_fn` need to resize the read images to that size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_train_images_input_fn(file_pattern, image_size=(64, 64, 3), shuffle=False,\n",
    "                 batch_size=32, num_epochs=None, buffer_size=4096):\n",
    "    \"\"\"get_input_fn exploits the `file_pattern` to create an input_fn that reads all the content\n",
    "    of the specified pattern, creating an object dataset.\n",
    "    \n",
    "    Args:\n",
    "        file_pattern: python string, the pattern of the file to read to generate the dataset\n",
    "        image_size: the new size of the read images\n",
    "        shuffle: True if the order of the elements in the generated dataset shold be randomized\n",
    "        batch_size: the size of the batches\n",
    "        num_epochs: the number of epochs to repeat the dataset before throwing an exeption; None is unlimited\n",
    "        buffer_size: how many images read before starting to generate output\n",
    "    Returns:\n",
    "        input_fn: the generated input_fn that returns a correctly instantiated iterator\n",
    "    \"\"\"\n",
    "    \n",
    "    def _img_string_to_tensor(image_string):\n",
    "        \"\"\"Decode an image as read from a `tf.decode_raw`, scales it between 0-1 and resize the\n",
    "        image as specified in the parent method.\n",
    "        Args:\n",
    "            image_string: the raw image tensor\n",
    "        Returns:\n",
    "            image_resize: image in [0,1] correctly resized\n",
    "        \"\"\"\n",
    "        \n",
    "        nonlocal image_size\n",
    "        \n",
    "        image_decoded = tf.image.decode_jpeg(image_string, channels=image_size[-1])\n",
    "        # The conversion to float automatically scales the values in [0., 1.]\n",
    "        image_decoded_as_float = tf.image.convert_image_dtype(image_decoded, dtype=tf.float32)\n",
    "        image_decoded = (image_decoded_as_float - 0.5) * 2\n",
    "        image_resized = tf.image.resize_images(image_decoded, size=image_size[:2])\n",
    "        \n",
    "\n",
    "        return image_resized\n",
    "\n",
    "    def _path_to_img(path):\n",
    "        \"\"\"Given the path of an image, returns the pair (image, label)\n",
    "        where image is the corretly resized image, and label is the label associated with it.\n",
    "        Args:\n",
    "            path: the path of the image to read\n",
    "        Returns:\n",
    "            (image_resized, label): the image, label pair associated the path\n",
    "        \"\"\"\n",
    "\n",
    "        image_string = tf.read_file(path) # read image and process it\n",
    "        image_resized = _img_string_to_tensor(image_string)\n",
    "\n",
    "        return image_resized\n",
    "    \n",
    "    def _input_fn():\n",
    "        \"\"\"The input function that builds the `tf.data.Dataset` object and instantiate\n",
    "        the iterator correctly ready to be use.\n",
    "        Returns:\n",
    "            the iterator associated to the built Dataset object.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Use the static method `list_files` that builds a dataset of all\n",
    "        # files matching this pattern.\n",
    "        dataset_path = tf.data.Dataset.list_files(file_pattern)\n",
    "\n",
    "        if shuffle:\n",
    "            dataset_path = dataset_path.apply(tf.contrib.data.shuffle_and_repeat(buffer_size, num_epochs))\n",
    "        else:\n",
    "            dataset_path = dataset_path.repeat(num_epochs)\n",
    "\n",
    "        # The map function maps the path to the pair (image, label)\n",
    "        dataset = dataset_path.map(_path_to_img)\n",
    "        dataset = dataset.apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\n",
    "        dataset = dataset.prefetch(buffer_size)\n",
    "        \n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        return iterator.get_next()\n",
    "\n",
    "    return _input_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good. We defined a function that will generate the correct `input_fn`s, for instance a possibile call for generating the training set is:\n",
    "```python\n",
    "train_files = os.path.join(os.getcwd(), 'dogscats', 'train', '**/*.jpg')\n",
    "train_input_fn = get_input_fn(train_files, shuffle=True, num_epochs=10)[0]\n",
    "```\n",
    "Since we're not interested in creating a conditional GAN, we'll just discard the `labels` parameter (keeping only the first value of the returned pair)\n",
    "\n",
    "Now we can start defining our `model_fn`, required to correclty work with `tf.estimator` API.\n",
    "\n",
    "Since we're working on images, we'll use an architecture created for this purpose DCGAN <sup>[3](#3)</sup>.\n",
    "\n",
    "## DCGAN: discriminator using tf.estimator\n",
    "\n",
    "The discriminator of DCGAN is common CNN architecture: a stack of convolutional layers that downsample the input image (without using pooling layers) followed by 2 fully connected layers.\n",
    "\n",
    "The output layer in the disciminator definition has the **linear** activation function (for the same reasong explained in the previous notebook).\n",
    "\n",
    "When working with `tf.estimator`, we have to follow the API specification. The `tf.estimator.Estimator.__init__` method requires as first parameter a `model_fn` function.\n",
    "\n",
    "The model function `model_fn` implements the ML algorithm and its behaviour in different conditions (train/eval/predict) and **must** have the following signature:\n",
    "\n",
    "```python\n",
    "def model_fn(\n",
    "   features, # This is batch_features from input_fn\n",
    "   labels,   # This is batch_labels from input_fn\n",
    "   mode,     # An instance of tf.estimator.ModeKeys\n",
    "   params):  # Additional configuration\n",
    "```\n",
    "\n",
    "and **must** return an instance of `tf.estimator.EstimatorSpec` that defines how the caller (the estimator) interacts with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_fn(features, labels, mode, params):\n",
    "    \"\"\"Build the Discriminator network.\n",
    "    Args:\n",
    "        features: a batch of images to classify, expected input shape (None, 64, 64 , 3)\n",
    "        labels: a batch of labels\n",
    "        mode: the tf.estimator.ModeKey\n",
    "        params: a dict of optional parameters\n",
    "    Returns:\n",
    "            The tf.estimator.EstimatorSpec that descibes the desired behaviour\n",
    "    \"\"\"\n",
    "    \n",
    "    # Let'suppose that features is a batch of both, generated and real images\n",
    "    \n",
    "    # In every mode, define the model\n",
    "    net =  tf.layers.conv2d(features, filters=128, activation=tf.nn.leaky_relu)\n",
    "    net = tf.layers.batch_normalization(net, training=True)\n",
    "    net = conv2d(net, filters=256, activation=tf.nn.leaky_relu)\n",
    "    net = tf.layers.batch_normalization(net, training=True)\n",
    "    net = conv2d(net, filters=512, activation=tf.nn.leaky_relu)\n",
    "    net = tf.layers.batch_normalization(net, training=True)\n",
    "    net = tf.reshape(net, (-1, net.shape[1] * net.shape[2] * net.shape[3]))\n",
    "    net = tf.layers.dense(net, 1)\n",
    "    D = tf.identity(net)\n",
    "    \n",
    "    # Let's suppose that labels is a batch of labels where 1 is the real image\n",
    "    # and 0 is the label associated to the genrated image\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=D, labels=labels))\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        train_op = tf.train.AdamOptmizer(1e-5).minimize(loss)\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, predictions=D, loss=loss, train_op=train_op)\n",
    "    # in PREDICT or EVAL mode, just return the estimaor spec with the requested mode\n",
    "    # and with the loss function (but NO the optimization step)\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator has been correctly defined, **unfortunately** we had to suppose that the `features, labels` parameters contain what we do expect: both generated and real images.\n",
    "\n",
    "*Is this really possibile when using the `tf.estimator` + `tf.data` API?*\n",
    "\n",
    "Tecnically yes, but with a lot of struggle (that someone else at Google already did!):\n",
    "\n",
    "- `tf.estimator.train` has been defined to train only one model at a time: how can we train both the generator and the discriminator using this function?\n",
    "- The dataset we defined, that could be used in any classification problem, should be changed in order to add the noise vector required by the generator network -> `tf.data.Dataset` is no more an advantage and we have to change our code?\n",
    "- How can we use two different `model_fn` (one for $G$ and one for $D$) and how can we connect the two models using a single estimator?\n",
    "\n",
    "Maybe the simple estimator is not enough...\n",
    "Lukily **an estimator tought to work with GANs has been introduced iin the TFGAN library: GANEstimator**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"1\">[1]</a>: https://www.tensorflow.org/guide/estimators\n",
    "\n",
    "<a id=\"2\">[2]</a>: For a more complete description of the `tf.data` API: https://www.tensorflow.org/guide/datasets\n",
    "\n",
    "<a id=\"3\">[3]</a>: Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks https://arxiv.org/pdf/1511.06434"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
